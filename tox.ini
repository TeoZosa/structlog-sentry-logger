[gh-actions]
python =
    3.9: py39, c_library
    3.10: py310, c_library
    3.11: py311, c_library, coverage

[tox]
skip_missing_interpreters = true
isolated_build = true
envlist =
    py3{9,10,11},
    c_library,
    coverage,
    package

[base_configs]
wheel = false
parallel_show_output = true

[testenv]
description = Run test suite under {basepython}
setenv =
    PIP_DISABLE_VERSION_CHECK = 1
    COVERAGE_FILE = {env:COVERAGE_FILE:{toxworkdir}/.coverage.{envname}}
    PY_COLORS = 1
deps = -r requirements-dev.txt
passenv =
    http_proxy
    https_proxy
    no_proxy
commands = pytest \
           --forked \
           --cov={toxinidir}/structlog_sentry_logger \
           --cov={toxinidir}/docs_src \
           --cov-config={toxinidir}/pyproject.toml \
           --junitxml={toxworkdir}/junit.{envname}.xml \
           --basetemp={envtmpdir} \
           -n={env:PYTEST_XDIST_PROC_NR:auto} \
           {env:TESTENV_SPECIFIED_PYTEST_FLAGS:} \
           {posargs:tests}
wheel = {[base_configs]wheel}
parallel_show_output = {[base_configs]parallel_show_output}

[testenv:c_library]
description = {[testenv]description} on C-compiled modules (i.e., NOT pure Python code)
setenv =
    {[testenv]setenv}
deps = {[testenv]deps}
passenv = {[testenv]passenv}
commands = {[testenv]commands}
wheel = true
parallel_show_output = {[testenv]parallel_show_output}

[testenv:py3{9,10,11}-benchmark-{pure_python,c_library}]
description = Run performance testing under {basepython}
setenv =
    {[testenv]setenv}
    pure_python: LIB_TYPE=pure_python
    c_library: LIB_TYPE=c_library
deps = {[testenv]deps}
passenv = {[testenv]passenv}
allowlist_externals = bash
commands =
# Run benchmark in a shell to incorporate dynamic tag in output file names
    bash -c '\
    SYS_PLATFORM=$(python -c "import sys; print(sys.platform.title())"); \
    BENCHMARK_FILE_TAG={env:LIB_TYPE}-$(make strong-version-tag); \
    BENCHMARK_FILE_PREFIX="{toxinidir}/.benchmarks/$\{SYS_PLATFORM\}-C{basepython}/$\{BENCHMARK_FILE_TAG\}"; \
    mkdir -p $\{BENCHMARK_FILE_PREFIX%/*\}; \
    pytest \
    --basetemp={envtmpdir} \
    --benchmark-cprofile=cumtime \
    --benchmark-disable-gc \
    --benchmark-histogram="$\{BENCHMARK_FILE_PREFIX\}" \
    --benchmark-json="$\{BENCHMARK_FILE_PREFIX\}".json \
    --benchmark-min-rounds={env:BENCHMARK_MIN_ROUNDS:10} \
    --benchmark-only \
    --benchmark-save="$\{BENCHMARK_FILE_TAG\}" \
    --benchmark-save-data \
    --benchmark-sort=mean \
    --benchmark-timer=time.process_time \
    --benchmark-verbose \
    --benchmark-warmup=on \
    {posargs:tests}'
wheel =
    pure_python: {[testenv]wheel}
    c_library: {[testenv:c_library]wheel}
parallel_show_output = {[testenv]parallel_show_output}

[testenv:mutmut]
setenv =
    {[testenv]setenv}
    JUNIT_XML_REPORT_OUTPUT_ROOT={toxworkdir}/junit.{envname}
    JUNIT_XML_REPORT_OUTPUT_PATH={env:JUNIT_XML_REPORT_OUTPUT_ROOT}.xml
    JUNIT_HTML_REPORT_OUTPUT_PATH={env:JUNIT_XML_REPORT_OUTPUT_ROOT}.html
# To read emoji in the mutmut source:
    LANG=en_US.UTF-8
deps =
    {[testenv]deps}
    nodeenv
passenv = {[testenv]passenv}
allowlist_externals = bash
commands =
# Run mutmut in a shell to remove escape metacharacters in "{[testenv]commands}"
# Note: mutmut 1 exit code is a fatal error.
#   Other non-zero exit codes correspond to mutant statuses but indicate that
#   mutmut itself was successful and therefore are ignored for this test environment.
#   see: https://github.com/boxed/mutmut/blob/8bd1331429234ba572471d2ab6854b38e880f25d/mutmut/__init__.py#L1258
    bash -c '\
        mutmut run \
            --paths-to-mutate=structlog_sentry_logger/ \
            --runner="{[testenv]commands}" \
            --tests-dir=tests/ || \
        MUTMUT_EXIT_CODE=$?; \
        if [[ "$\{MUTMUT_EXIT_CODE\}" -eq 1 ]]; \
            then \
                exit "$\{MUTMUT_EXIT_CODE\}"; \
        fi'
    mutmut results

# Export JUnit XML results to user-friendly static HTML page
    bash -c '\
        mutmut junitxml \
        > {env:JUNIT_XML_REPORT_OUTPUT_PATH}'

    nodeenv --python-virtualenv --jobs=8
    npm install -g --no-package-lock --no-save xunit-viewer
    # Inside of the virtualenv, '-g' installs into the virtualenv,
    # as opposed to installing into the local `node_modules`.

    xunit-viewer \
        --results {env:JUNIT_XML_REPORT_OUTPUT_PATH} \
        --title="Mutation Tests Report" \
        --output {env:JUNIT_HTML_REPORT_OUTPUT_PATH}
    bash -c '\
        echo -e "Test report available at \033[4;36m \
            {env:JUNIT_HTML_REPORT_OUTPUT_PATH} \
            \033[0m"'
wheel = {[testenv]wheel}

[testenv:coverage]
description = [Run locally after tests]: Combine coverage data and create reports;
              generates a diff coverage against `{env:DIFF_AGAINST:origin/master}`
              (can be changed by setting `DIFF_AGAINST` env var)
deps =
    coverage[toml]
    diff_cover
skip_install = true
passenv =
    {[testenv]passenv}
    DIFF_AGAINST
setenv = COVERAGE_FILE={toxworkdir}/.coverage
commands =
    coverage combine {toxworkdir}
    coverage report
    coverage xml -o {toxworkdir}/coverage.xml
    coverage html -d {toxworkdir}/htmlcov
    coverage json -o {toxworkdir}/coverage.json --pretty-print
    diff-cover {toxworkdir}/coverage.xml \
        --compare-branch={env:DIFF_AGAINST:origin/master} \
        --diff-range-notation '..'
depends =
    py3{9,10,11}
parallel_show_output = {[testenv]parallel_show_output}

[testenv:precommit]
description = Run `pre-commit` hooks to auto-format and lint the codebase
deps =
    importlib-metadata
    pre-commit
    # Pre-commit hooks that rely on finding their executables in the `.tox/precommit/bin`
    mypy
    # Dependencies that are imported in source code and therefore needed for above pre-commit hook execution
    emoji
    pytest
    pytest-benchmark
    pytest-mock
    sphinx
    # PEP 561 compliant stub packages for mypy
    types-emoji
    # Prod dependencies
    -r requirements.txt
skip_install = true
; For shfmt
setenv = GOCACHE={envdir}/go-build
passenv =
    HOMEPATH  # needed on Windows
    PROGRAMDATA  # needed on Windows
    SKIP # hook ids to skip
    TERM # (e.g. for mypy color output (https://github.com/tox-dev/tox/issues/1441#issuecomment-548063521))
commands = pre-commit run {posargs} -vv --all-files --color always
           python -c 'print("hint: run `make install-pre-commit-hooks` to add checks as pre-commit hook")'
wheel = {[base_configs]wheel}

[testenv:package]
description = Build Python package and validate its long description
deps =
    poetry >= 1.1.2
    mypy >= 0.910
    twine >= 1.12.1
    orjson >= 3.6.4
    readme-renderer[md] >= 24.0
skip_install = false
commands = poetry build
           twine check {toxinidir}/dist/*

[testenv:security]
skip_install = true
deps = safety
commands = safety check --full-report -r {toxinidir}/requirements-all.txt \
    # CVE-2019-8341
    --ignore=70612 \
    # CVE-2022-42969
    --ignore=51457 \
    # CVE-2023-24816
    --ignore=53269

[testenv:docs]
extras =
    docs
passenv = TERM
setenv =
    PYTHONHASHSEED = 0
commands =
    sphinx-build -n -T -W -b html -d {envtmpdir}/doctrees docs/source docs/_build/html
    sphinx-build -n -T -W -b doctest -d {envtmpdir}/doctrees docs/source docs/_build/html
